<!DOCTYPE html>
<html lang="en">
    <head prefix="og: https://ogp.me/ns#">
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="color-scheme" content="light dark">
  
  <title>使用SVM进行垃圾短信分类 - Mr.K</title>
  
    <link rel="shortcut icon" href="/favicon.ico">
  
  
    <link rel='manifest' href='/manifest.json'>
  

  
  
  
  <meta property="og:title" content="使用SVM进行垃圾短信分类 - Mr.K" />
  
  <meta property="og:type" content="article" />
  
  <meta property="og:url" content="http://example.com/2023/11/07/%E4%BD%BF%E7%94%A8SVM%E8%BF%9B%E8%A1%8C%E5%9E%83%E5%9C%BE%E7%9F%AD%E4%BF%A1%E5%88%86%E7%B1%BB/index.html" />
  
  <meta property="og:image" content="/favicon.ico" />
  
  <meta property="og:article:published_time" content="2023-11-07T12:32:52.000Z" />
  
  <meta property="og:article:author" content="Kjr" />
  
  

  
<link rel="stylesheet" href="/css/var.css">

  
<link rel="stylesheet" href="/css/main.css">

  
<link rel="stylesheet" href="/css/typography.css">

  
<link rel="stylesheet" href="/css/code-highlighting.css">

  
<link rel="stylesheet" href="/css/components.css">

  
<link rel="stylesheet" href="/css/nav.css">

  
<link rel="stylesheet" href="/css/paginator.css">

  
<link rel="stylesheet" href="/css/footer.css">

  
<link rel="stylesheet" href="/css/post-list.css">

  
  
<link rel="stylesheet" href="/css/rainbow-banner.css">

  
  
  
<link rel="stylesheet" href="/css/toc.css">

  
  
  
  
  
<link rel="stylesheet" href="/css/post.css">

  
  
  
  
  

  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.3.0"></head>
    <body
        data-color-scheme="auto"
        data-uppercase-categories="true"
        
        data-rainbow-banner="true"
        data-rainbow-banner-shown="auto"
        data-rainbow-banner-month="6"
        data-rainbow-banner-colors="#e50000,#ff8d00,#ffee00,#008121,#004cff,#760188"
        
        data-config-root="/"
        
        data-toc="true"
        data-toc-max-depth="2"
        
        
    >
        <nav id="theme-nav">
    <div class="inner">
        <a class="title" href="/">Blog</a>
        <div class="nav-arrow"></div>
        <div class="nav-items">
            <a class="nav-item nav-item-home" href="/">Home</a>
            
            
            <a class="nav-item" href="/archives">Archives</a>
            
            
            
            <a class="nav-item" href="/tags">Tags</a>
            
            
            
            <a class="nav-item" href="/categories">Categories</a>
            
            
            
            <a class="nav-item" href="/about">About</a>
            
            
            
            <a class="nav-item" target="_blank" rel="noopener" href="https://space.bilibili.com/344213153?spm_id_from=333.1007.0.0">Bilibili.</a>
            
            
            
            <a class="nav-item nav-item-github nav-item-icon" href="https://github.com/kinferiority" target="_blank" aria-label="GitHub">&nbsp;</a>
            
            
            
            <a class="nav-item nav-item-search nav-item-icon" href="/search" target="_blank" aria-label="Search">&nbsp;</a>
            
            
        </div>
    </div>
</nav>
        
<article class="post">
    <div class="meta">
        
        <div class="categories text-uppercase">
        
            <a href="/categories/ML-Code/">ML_Code</a>
        
        </div>
        

        
        <div class="date" id="date">
            <span>November</span>
            <span>7,</span>
            <span>2023</span>
        </div>
        

        <h2 class="title">使用SVM进行垃圾短信分类</h2>
    </div>

    <div class="divider"></div>

    <div class="content">
        <h1 id="使用SVM进行垃圾短信分类"><a href="#使用SVM进行垃圾短信分类" class="headerlink" title="使用SVM进行垃圾短信分类"></a>使用SVM进行垃圾短信分类</h1><h2 id="1-数据集"><a href="#1-数据集" class="headerlink" title="1.数据集"></a>1.数据集</h2><p>​    <a target="_blank" rel="noopener" href="https://www.kaggle.com/code/sadeghjalalian/96-accuracy-svm-spam-text-message-classification/comments">来自kaggle</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Category,Message</span><br><span class="line">ham,"Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat..."</span><br><span class="line">ham,Ok lar... Joking wif u oni...</span><br><span class="line">spam,Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 08452810075over18's</span><br><span class="line">ham,U dun say so early hor... U c already then say...</span><br></pre></td></tr></table></figure>
<h3 id="1-1阅读数据集相关信息"><a href="#1-1阅读数据集相关信息" class="headerlink" title="1.1阅读数据集相关信息"></a>1.1阅读数据集相关信息</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">data = pd.read_csv("SPAM text message 20170820 - Data.csv")</span><br><span class="line">print(data.head())</span><br><span class="line">print(data.info())</span><br><span class="line">print(data.groupby("Category").describe())</span><br><span class="line">'''</span><br><span class="line">         Message                                                               </span><br><span class="line">           count unique                                                top freq</span><br><span class="line">Category                                                                       </span><br><span class="line">ham         4825   4516                             Sorry, I'll call later   30</span><br><span class="line">spam         747    641  Please call our customer service representativ...    4</span><br><span class="line">'''</span><br></pre></td></tr></table></figure>
<h3 id="1-2创建饼图"><a href="#1-2创建饼图" class="headerlink" title="1.2创建饼图"></a>1.2创建饼图</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># 创建新列length统计信息长度</span><br><span class="line">data['Length'] = data['Message'].apply(len)</span><br><span class="line">print(data.head())</span><br><span class="line"></span><br><span class="line"># 展示数据分布百分比</span><br><span class="line">explode = (0.1, 0)</span><br><span class="line"># explode用于指定是否要将某个扇形从饼图中分离出来。</span><br><span class="line"># 在这里，第一个元素是0.1，表示将"ham"类别的扇形分离出来，而第二个元素是0，表示"spam"类别的扇形不分离。</span><br><span class="line">fig1, ax1 = plt.subplots(figsize=(12, 7))</span><br><span class="line"># plt.subplots 通常与 ax 对象一起使用，ax 对象是子图的引用，你可以使用它来绘制图形元素。</span><br><span class="line">ax1.pie(data['Category'].value_counts(), explode=explode, labels=['ham', 'spam'], autopct='%1.1f%%',</span><br><span class="line">        shadow=True)</span><br><span class="line">"""</span><br><span class="line">data['Category'].value_counts()：返回Pandas Series 对象，这个 Series 对象是一维数据结构，其中索引是类别名称，数据是每个类别出现的次数。</span><br><span class="line">这部分计算了 "Category" 列中各个类别的计数，即 "ham" 和 "spam" 的数量。</span><br><span class="line">explode=explode：使用之前定义的explode变量来分离"ham"类别的扇形。</span><br><span class="line">labels=['ham', 'spam']：设置饼图中扇形的标签，分别为 "ham" 和 "spam"。</span><br><span class="line">autopct='%1.1f%%'：设置扇形上显示的百分比格式，保留一位小数。</span><br><span class="line">shadow=True：添加阴影效果，使饼图看起来有立体感</span><br><span class="line"></span><br><span class="line">"""</span><br><span class="line">ax1.axis('equal')</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/2023/11/07/%E4%BD%BF%E7%94%A8SVM%E8%BF%9B%E8%A1%8C%E5%9E%83%E5%9C%BE%E7%9F%AD%E4%BF%A1%E5%88%86%E7%B1%BB/image-20231107202214879.png" alt="image-20231107202214879"></p>
<h3 id="1-3创建直方图"><a href="#1-3创建直方图" class="headerlink" title="1.3创建直方图"></a>1.3创建直方图</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 创建一个 Matplotlib 图形对象，并设置图形的大小为 10x6 英寸。这将是后续绘图的容器。</span><br><span class="line">plt.figure(figsize=(10, 6))</span><br><span class="line"># hist 是直方图的绘制方法，而 bins 参数用于指定直方图的箱子数量。</span><br><span class="line">data['Length'].plot.hist(bins=150)</span><br><span class="line"># bins 参数用于指定直方图的箱子数量，而箱子数量代表着数据分布的粒度</span><br><span class="line"># 箱子数量过多可能会使直方图过于复杂，箱子数量过少可能会损失一些分布细节。</span><br><span class="line">plt.show()</span><br><span class="line">print(data["Length"].describe())</span><br><span class="line"></span><br><span class="line">print(data[data['Length'] == 910]['Message'].iloc[0])</span><br><span class="line">"""使用布尔索引，从 DataFrame df 中选择所有 "Length" 列的值等于 910 的行。</span><br><span class="line">这将返回一个子集的DataFrame，其中只包含满足条件的行。</span><br><span class="line">['Message']：接着选择这个子集中的 "Message" 列。</span><br><span class="line">.iloc[0]：最后，使用 .iloc[0] 来获取这个子集中的第一个元素，也就是第一条消息。</span><br><span class="line">"""</span><br></pre></td></tr></table></figure>
<p><img src="/2023/11/07/%E4%BD%BF%E7%94%A8SVM%E8%BF%9B%E8%A1%8C%E5%9E%83%E5%9C%BE%E7%9F%AD%E4%BF%A1%E5%88%86%E7%B1%BB/image-20231107202303251.png" alt="image-20231107202303251"></p>
<h2 id="2-数据处理"><a href="#2-数据处理" class="headerlink" title="2.数据处理"></a>2.数据处理</h2><h3 id="2-1数据清理"><a href="#2-1数据清理" class="headerlink" title="2.1数据清理"></a>2.1数据清理</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># 数据清理</span><br><span class="line">import string</span><br><span class="line">from nltk.corpus import stopwords</span><br><span class="line"></span><br><span class="line">"""</span><br><span class="line">stopwords 模块用于提供停用词列表。</span><br><span class="line">停用词是在文本分析中通常会被忽略的常见单词，因为它们通常不携带有用的信息，</span><br><span class="line">例如 "the," "and," "is," "in" 等。停用词通常在文本预处理的过程中被去除，</span><br><span class="line">以便在分析中集中注意力于包含更多信息的单词。</span><br><span class="line">"""</span><br><span class="line">def text_process(mess):</span><br><span class="line">    """</span><br><span class="line">        Takes in a string of text, then performs the following:</span><br><span class="line">        1. Remove all punctuation</span><br><span class="line">        2. Remove all stopwords</span><br><span class="line">        3. Returns a list of the cleaned text</span><br><span class="line">    """</span><br><span class="line">    # 检查字符是否在标点符号内</span><br><span class="line">    nopunc = [char for char in mess if char not in string.punctuation]</span><br><span class="line">    # nopunc 列表中的每个元素都代表 mess 中的一个字符，包括字母、数字和其他符号，只是去除了标点符号</span><br><span class="line">    # 再次连接字符以形成字符串。</span><br><span class="line">    nopunc = ''.join(nopunc)</span><br><span class="line">    # 剔除所有停止词</span><br><span class="line">    # stopwords.words('language') 来获取特定语言的停用词列表，其中 'language' 是你所需语言的名称，例如 'english' 表示英语。</span><br><span class="line">    # nopunc.split()返回的列表中每个元素一个词</span><br><span class="line">    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 测试</span><br><span class="line">print(data['Message'].head(10).apply(text_process))</span><br></pre></td></tr></table></figure>


<h3 id="2-2CountVectorizer"><a href="#2-2CountVectorizer" class="headerlink" title="2.2CountVectorizer"></a>2.2CountVectorizer</h3><p>CountVectorizer 是用于将文本数据转换为词袋（Bag of Words）表示的文本特征提取工具之一。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.feature_extraction.text import CountVectorizer</span><br><span class="line"></span><br><span class="line"># CountVectorizer 是用于将文本数据转换为词袋（Bag of Words）表示的文本特征提取工具之一。</span><br><span class="line">"""</span><br><span class="line">对文本进行分词：CountVectorizer 将文本数据分解为单词（或者其他指定的标记单元，如n-grams）。</span><br><span class="line">构建词汇表：它创建一个包含文本中所有不同单词的词汇表。这个词汇表会作为特征空间的基础。</span><br><span class="line">计算单词出现的频次：对于每个文档（或句子），CountVectorizer 统计每个单词在文档中出现的次数，然后将这些计数作为特征向量的值。</span><br><span class="line">返回稀疏矩阵：CountVectorizer 返回一个稀疏矩阵，其中每行表示一个文档（或句子），每列代表一个词汇表中的单词，矩阵中的元素是单词在文档中出现的次数。</span><br><span class="line">"""</span><br><span class="line">bow_transformer = CountVectorizer(analyzer=text_process).fit(data['Message'])</span><br><span class="line"># 将文本处理函数传递给 analyzer，以便在构建词汇表时进行文本预处理。这允许你在构建词汇表时执行文本清洗、分词、去除停用词等操作。</span><br><span class="line"># 打印单词数</span><br><span class="line">print(len(bow_transformer.vocabulary_))</span><br><span class="line"></span><br><span class="line"># 测试</span><br><span class="line">message1 = data['Message'][1]</span><br><span class="line">print(message1)</span><br><span class="line"></span><br><span class="line">bow1 = bow_transformer.transform([message1])</span><br><span class="line"># bow1 存储的是一个稀疏矩阵（sparse matrix）。</span><br><span class="line"># 在这个上下文中，bow1 是将示例文本 message1 转化为词袋表示的结果。</span><br><span class="line">print(bow1)</span><br><span class="line">"""</span><br><span class="line"> (0, 3062)  1 表示词汇表中索引为 3062 的单词出现了1次，这个数字 1 是该单词在这个文档中的频数，而不是该单词的向量表示。</span><br><span class="line">  (0, 7698) 1</span><br><span class="line">  CountVectorizer 通常会生成类似于一种独热编码（one-hot encoding）的向量表示。</span><br><span class="line">"""</span><br><span class="line">print(bow1.shape)  # (1, 11422) 11422为序列限制及词汇表长度</span><br><span class="line"></span><br><span class="line"># 获取词汇表</span><br><span class="line">vocab = bow_transformer.get_feature_names_out()</span><br><span class="line">print(vocab[11069])</span><br><span class="line"></span><br><span class="line"># 将整个Message列转为稀疏矩阵</span><br><span class="line">messages_bow = bow_transformer.transform(data['Message'])</span><br><span class="line">print(f'稀疏矩阵维度{messages_bow.shape}')</span><br><span class="line"># 计算稀疏度 稀疏矩阵中的非零元素数量与矩阵总元素数量的比值</span><br><span class="line">sparsity = (100 * messages_bow.nnz / (messages_bow.shape[0] * messages_bow.shape[1]))</span><br><span class="line">print(f'稀疏度：{sparsity}')</span><br></pre></td></tr></table></figure>
<h3 id="2-3TF-IDF"><a href="#2-3TF-IDF" class="headerlink" title="2.3TF-IDF"></a>2.3TF-IDF</h3><p>TF-IDF是一种用于文本数据的特征提取方法，它可以量化文本文档中各个单词的重要性。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.feature_extraction.text import TfidfTransformer</span><br><span class="line"></span><br><span class="line">tfid_transformer = TfidfTransformer().fit(messages_bow)</span><br><span class="line"># 进行 TF-IDF 转换 tfidf4 包含了文本数据的 TF-IDF 表示，其中每个元素代表文档中单词的TF-IDF权重。</span><br><span class="line">tfid4 = tfid_transformer.transform(messages_bow)</span><br><span class="line">print(tfid4)</span><br><span class="line"></span><br><span class="line">"""一步到位使用TfidfVectorizer</span><br><span class="line">from sklearn.feature_extraction.text import TfidfVectorizer</span><br><span class="line"></span><br><span class="line"># 创建TfidfVectorizer对象</span><br><span class="line">tfidf_vectorizer = TfidfVectorizer()</span><br><span class="line"></span><br><span class="line"># 将文本数据转化为TF-IDF权重表示</span><br><span class="line">tfidf_matrix = tfidf_vectorizer.fit_transform(data['Message'])</span><br><span class="line"></span><br><span class="line"># 输出TF-IDF权重矩阵</span><br><span class="line">print(tfidf_matrix)</span><br><span class="line"></span><br><span class="line">"""</span><br><span class="line"></span><br><span class="line"># 使用随机森林模型</span><br><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line"></span><br><span class="line">classifier = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)</span><br><span class="line">"""</span><br><span class="line">n_estimators=10：这是随机森林中的决策树数量。在这里，设置为 10，表示随机森林将包含 10 个决策树。随机森林通过集成多个决策树的预测来提高模型的性能。</span><br><span class="line">criterion='entropy'：这是用于测量分割节点质量的标准。在这里，使用的是信息熵（entropy）来评估分割的质量。信息熵是一种用于度量不纯度的指标，它在决策树中用于选择最佳分割点。</span><br><span class="line">random_state=0：这是随机种子，用于控制随机性。设置了一个特定的随机种子（0），以确保在每次运行代码时获得相同的结果。这对于实验的可重复性很有用。</span><br><span class="line">"""</span><br><span class="line">classifier.fit(tfid4, data['Category'])</span><br><span class="line"># classifier.fit(X, y) 是用于训练模型的常见方法，其中 X 表示特征矩阵，y 表示目标变量或标签。</span><br><span class="line"></span><br><span class="line"># 测试单条信息</span><br><span class="line">print(f'预测：{classifier.predict(tfid4[0])}')</span><br><span class="line">print(f"实际：{data['Category'][0]}")  # data.Category[0]</span><br><span class="line">all_predictions = classifier.predict(tfid4)</span><br><span class="line">print(all_predictions)</span><br><span class="line"># 创建分类报告</span><br><span class="line">from sklearn.metrics import classification_report</span><br><span class="line"></span><br><span class="line">print(classification_report(data['Category'], all_predictions))</span><br><span class="line"></span><br><span class="line">from sklearn import metrics</span><br><span class="line"></span><br><span class="line">print("Accuracy:", metrics.accuracy_score(data['Category'], all_predictions))</span><br></pre></td></tr></table></figure>


<h3 id="2-4划分数据集进行训练、测试"><a href="#2-4划分数据集进行训练、测试" class="headerlink" title="2.4划分数据集进行训练、测试"></a>2.4划分数据集进行训练、测试</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rom sklearn.model_selection import train_test_split</span><br><span class="line"></span><br><span class="line">msg_train, msg_test, label_train, label_test = train_test_split(data['Message'], data['Category'], test_size=0.2)</span><br><span class="line">print(len(msg_train), len(msg_test), len(msg_train) + len(msg_test))  # 4457 1115</span><br></pre></td></tr></table></figure>
<h2 id="3-Pipeline"><a href="#3-Pipeline" class="headerlink" title="3 Pipeline"></a>3 Pipeline</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Pipeline 是 scikit-learn（sklearn）库中的一个工具类，用于将多个数据处理步骤和机器学习模型组合成一个单一的对象。</span><br><span class="line">在 Pipeline 中的 (步骤名称, 步骤对象) 形式的元组表示了每个步骤的标识名称和实际的数据处理或模型对象</span><br><span class="line">Pipeline 会按照元组的顺序执行这些步骤，从第一个步骤开始，然后将每个步骤的输出作为下一个步骤的输入。</span><br><span class="line">这种组合能够确保数据流畅地通过整个流程，同时保持了代码的清晰和可维护性。</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line"></span><br><span class="line">pipeline = Pipeline([</span><br><span class="line">    ('bow', CountVectorizer(analyzer=text_process)),  # 将文本数据转化为词袋表示</span><br><span class="line">    ('tfidf', TfidfTransformer()),  # 对词袋表示进行 TF-IDF 转换</span><br><span class="line">    ('classifier', RandomForestClassifier())  # 使用随机森林分类器进行文本分类。</span><br><span class="line">])</span><br><span class="line">pipeline.fit(msg_train, label_train)</span><br><span class="line">predictions = pipeline.predict(msg_test)</span><br><span class="line"></span><br><span class="line"># 构建混淆矩阵</span><br><span class="line">from sklearn.metrics import confusion_matrix, classification_report</span><br><span class="line"></span><br><span class="line">cm = confusion_matrix(label_test, predictions)</span><br><span class="line">class_names = [0, 1]</span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">tick_marks = np.arange(len(class_names))</span><br><span class="line">plt.xticks(tick_marks, class_names)</span><br><span class="line">plt.yticks(tick_marks, class_names)</span><br><span class="line"># 创建热力图</span><br><span class="line">sns.heatmap(pd.DataFrame(cm), annot=True, cmap='BuPu', fmt='g')</span><br><span class="line">'''</span><br><span class="line">pd.DataFrame(cm)：将混淆矩阵 cm 转化为 Pandas DataFrame，以便更好地处理和可视化数据。</span><br><span class="line">annot=True：在热力图中显示数值标签，即在每个热力图单元格中显示混淆矩阵中的数值。</span><br><span class="line">cmap='BuPu'：指定了热力图的颜色映射，这里使用了 'BuPu'，表示蓝紫色调的颜色映射。</span><br><span class="line">fmt='g'：指定了如何格式化显示数值标签。'g' 表示通用格式，可以自动选择合适的格式以显示数值。</span><br><span class="line">'''</span><br><span class="line"># 在混淆矩阵可视化中，将 x 轴标签放在顶部可能会更有意义，</span><br><span class="line"># 因为混淆矩阵通常以左上角作为开始点，而 x 轴标签代表了预测的类别。</span><br><span class="line">ax.xaxis.set_label_position('top')</span><br><span class="line"># 设置 y=1.1 会使标题稍微向上偏移，超出图的顶部，从而提高标题的垂直位置</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.title('Confusion matrix', y=1.1)</span><br><span class="line">plt.ylabel('Actual label')</span><br><span class="line">plt.xlabel('Predicted label')</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">print(classification_report(predictions,label_test))</span><br><span class="line">from sklearn import metrics</span><br><span class="line">print("Accuracy:",metrics.accuracy_score(predictions,label_test))</span><br></pre></td></tr></table></figure>
<p><img src="/2023/11/07/%E4%BD%BF%E7%94%A8SVM%E8%BF%9B%E8%A1%8C%E5%9E%83%E5%9C%BE%E7%9F%AD%E4%BF%A1%E5%88%86%E7%B1%BB/image-20231107203137449.png" alt="image-20231107203137449"></p>
<h3 id="命令行输出的所有结果如下"><a href="#命令行输出的所有结果如下" class="headerlink" title="命令行输出的所有结果如下"></a>命令行输出的所有结果如下</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br></pre></td><td class="code"><pre><span class="line">/Users/jrk/anaconda3/envs/kjr/bin/python /Users/jrk/PycharmProjects/SVM/SVM_Spam_Text_Message_Classification.py </span><br><span class="line">  Category                                            Message</span><br><span class="line">0      ham  Go until jurong point, crazy.. Available only ...</span><br><span class="line">1      ham                      Ok lar... Joking wif u oni...</span><br><span class="line">2     spam  Free entry in 2 a wkly comp to win FA Cup fina...</span><br><span class="line">3      ham  U dun say so early hor... U c already then say...</span><br><span class="line">4      ham  Nah I don't think he goes to usf, he lives aro...</span><br><span class="line">&lt;class 'pandas.core.frame.DataFrame'&gt;</span><br><span class="line">RangeIndex: 5572 entries, 0 to 5571</span><br><span class="line">Data columns (total 2 columns):</span><br><span class="line"> #   Column    Non-Null Count  Dtype </span><br><span class="line">---  ------    --------------  ----- </span><br><span class="line"> 0   Category  5572 non-null   object</span><br><span class="line"> 1   Message   5572 non-null   object</span><br><span class="line">dtypes: object(2)</span><br><span class="line">memory usage: 87.2+ KB</span><br><span class="line">None</span><br><span class="line">         Message                                                               </span><br><span class="line">           count unique                                                top freq</span><br><span class="line">Category                                                                       </span><br><span class="line">ham         4825   4516                             Sorry, I'll call later   30</span><br><span class="line">spam         747    641  Please call our customer service representativ...    4</span><br><span class="line">  Category                                            Message  Length</span><br><span class="line">0      ham  Go until jurong point, crazy.. Available only ...     111</span><br><span class="line">1      ham                      Ok lar... Joking wif u oni...      29</span><br><span class="line">2     spam  Free entry in 2 a wkly comp to win FA Cup fina...     155</span><br><span class="line">3      ham  U dun say so early hor... U c already then say...      49</span><br><span class="line">4      ham  Nah I don't think he goes to usf, he lives aro...      61</span><br><span class="line">count    5572.000000</span><br><span class="line">mean       80.368988</span><br><span class="line">std        59.926946</span><br><span class="line">min         2.000000</span><br><span class="line">25%        35.750000</span><br><span class="line">50%        61.000000</span><br><span class="line">75%       122.000000</span><br><span class="line">max       910.000000</span><br><span class="line">Name: Length, dtype: float64</span><br><span class="line">For me the love should start with attraction.i should feel that I need her every time around me.she should be the first thing which comes in my thoughts.I would start the day and end it with her.she should be there every time I dream.love will be then when my every breath has her name.my life should happen around her.my life will be named to her.I would cry for her.will give all my happiness and take all her sorrows.I will be ready to fight with anyone for her.I will be in love when I will be doing the craziest things for her.love will be when I don't have to proove anyone that my girl is the most beautiful lady on the whole planet.I will always be singing praises for her.love will be when I start up making chicken curry and end up makiing sambar.life will be the most beautiful then.will get every morning and thank god for the day because she is with me.I would like to say a lot..will tell later..</span><br><span class="line">0    [Go, jurong, point, crazy, Available, bugis, n...</span><br><span class="line">1                       [Ok, lar, Joking, wif, u, oni]</span><br><span class="line">2    [Free, entry, 2, wkly, comp, win, FA, Cup, fin...</span><br><span class="line">3        [U, dun, say, early, hor, U, c, already, say]</span><br><span class="line">4    [Nah, dont, think, goes, usf, lives, around, t...</span><br><span class="line">5    [FreeMsg, Hey, darling, 3, weeks, word, back, ...</span><br><span class="line">6    [Even, brother, like, speak, treat, like, aids...</span><br><span class="line">7    [per, request, Melle, Melle, Oru, Minnaminungi...</span><br><span class="line">8    [WINNER, valued, network, customer, selected, ...</span><br><span class="line">9    [mobile, 11, months, U, R, entitled, Update, l...</span><br><span class="line">Name: Message, dtype: object</span><br><span class="line">11422</span><br><span class="line">Ok lar... Joking wif u oni...</span><br><span class="line">  (0, 2449)	1</span><br><span class="line">  (0, 3062)	1</span><br><span class="line">  (0, 7698)	1</span><br><span class="line">  (0, 8587)	1</span><br><span class="line">  (0, 10695)	1</span><br><span class="line">  (0, 11069)	1</span><br><span class="line">(1, 11422)</span><br><span class="line">wif</span><br><span class="line">稀疏矩阵维度(5572, 11422)</span><br><span class="line">稀疏度：0.07934838914285262</span><br><span class="line">  (0, 11160)	0.23026685592418913</span><br><span class="line">  (0, 10962)	0.19073428545061483</span><br><span class="line">  (0, 8914)	0.24704652376837993</span><br><span class="line">  (0, 8333)	0.17046869292195632</span><br><span class="line">  (0, 7665)	0.26403384065473806</span><br><span class="line">  (0, 7552)	0.31253856260694546</span><br><span class="line">  (0, 6934)	0.1834692413608692</span><br><span class="line">  (0, 6903)	0.15158474664662352</span><br><span class="line">  (0, 6214)	0.18915557732842803</span><br><span class="line">  (0, 5766)	0.24984711892976424</span><br><span class="line">  (0, 5215)	0.26870593862526665</span><br><span class="line">  (0, 5214)	0.29835184088197164</span><br><span class="line">  (0, 4651)	0.31253856260694546</span><br><span class="line">  (0, 2058)	0.24203960256420656</span><br><span class="line">  (0, 1480)	0.31253856260694546</span><br><span class="line">  (0, 1107)	0.2882862016308418</span><br><span class="line">  (1, 11069)	0.40059731892909933</span><br><span class="line">  (1, 10695)	0.20657545787061052</span><br><span class="line">  (1, 8587)	0.5043175634668231</span><br><span class="line">  (1, 7698)	0.3767229062690876</span><br><span class="line">  (1, 3062)	0.2911862458354422</span><br><span class="line">  (1, 2449)	0.5619631532224204</span><br><span class="line">  (2, 11120)	0.19104387220509106</span><br><span class="line">  (2, 11081)	0.15898145347176754</span><br><span class="line">  (2, 10683)	0.13995540820792943</span><br><span class="line">  :	:</span><br><span class="line">  (5568, 6879)	0.31367469776242124</span><br><span class="line">  (5568, 6688)	0.47781076401785183</span><br><span class="line">  (5568, 6351)	0.5575721048646767</span><br><span class="line">  (5568, 4878)	0.3853122086093004</span><br><span class="line">  (5569, 10196)	0.520467167163554</span><br><span class="line">  (5569, 8249)	0.4328299709057074</span><br><span class="line">  (5569, 3719)	0.520467167163554</span><br><span class="line">  (5569, 3226)	0.520467167163554</span><br><span class="line">  (5570, 11003)	0.20434525994453323</span><br><span class="line">  (5570, 10784)	0.22867843486502568</span><br><span class="line">  (5570, 9912)	0.22380228376189748</span><br><span class="line">  (5570, 8417)	0.22651675757217207</span><br><span class="line">  (5570, 7797)	0.17243888184764117</span><br><span class="line">  (5570, 7391)	0.3071475234812021</span><br><span class="line">  (5570, 7284)	0.26786677935500575</span><br><span class="line">  (5570, 6981)	0.2641640440122445</span><br><span class="line">  (5570, 6796)	0.294185812624235</span><br><span class="line">  (5570, 6696)	0.2008376534326777</span><br><span class="line">  (5570, 6279)	0.2607702439080329</span><br><span class="line">  (5570, 5248)	0.302353515740512</span><br><span class="line">  (5570, 5052)	0.36357250744470165</span><br><span class="line">  (5570, 4506)	0.3470692575834817</span><br><span class="line">  (5571, 10645)	0.539218119882165</span><br><span class="line">  (5571, 8345)	0.48542915408134024</span><br><span class="line">  (5571, 3429)	0.6881877327870772</span><br><span class="line">预测：['ham']</span><br><span class="line">实际：ham</span><br><span class="line">['ham' 'ham' 'spam' ... 'ham' 'ham' 'ham']</span><br><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">         ham       1.00      1.00      1.00      4825</span><br><span class="line">        spam       1.00      0.97      0.99       747</span><br><span class="line"></span><br><span class="line">    accuracy                           1.00      5572</span><br><span class="line">   macro avg       1.00      0.99      0.99      5572</span><br><span class="line">weighted avg       1.00      1.00      1.00      5572</span><br><span class="line"></span><br><span class="line">Accuracy: 0.9965900933237617</span><br><span class="line">4457 1115 5572</span><br><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">         ham       1.00      0.97      0.98       997</span><br><span class="line">        spam       0.79      0.99      0.88       118</span><br><span class="line"></span><br><span class="line">    accuracy                           0.97      1115</span><br><span class="line">   macro avg       0.89      0.98      0.93      1115</span><br><span class="line">weighted avg       0.98      0.97      0.97      1115</span><br><span class="line"></span><br><span class="line">Accuracy: 0.9704035874439462</span><br><span class="line"></span><br><span class="line">进程已结束，退出代码为 0</span><br><span class="line"></span><br></pre></td></tr></table></figure>

    </div>

    
    <div class="about">
        <h1>About this Post</h1>
        <div class="details">
            <p>This post is written by Kjr, licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc/4.0">CC BY-NC 4.0</a>.</p>
        </div>
        
        <p class="tags">
            
            <i class="icon"></i>
            <a href="/tags/SVM/" class="tag">#SVM</a>
        </p>
        
    </div>
    

    <div class="container post-prev-next">
        <a class="next"></a>
        
        <a href="/2023/11/07/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/" class="prev">
            <div>
                <div class="text">
                    <p class="label">Previous</p>
                    <h3 class="title">深度学习框架</>
                </div>
            </div>
        </a>
        
    </div>

    
        
        
    
</article>

        <footer>
    <div class="inner">
        <div class="links">
            
            <div class="group">
                <h2 class="title">Blog</h2>
                
                <a href="/" class="item">Blog</a>
                
                <a href="/archives" class="item">Archives</a>
                
                <a href="/tags" class="item">Tags</a>
                
                <a href="/categories" class="item">Categories</a>
                
                <a href="/search" class="item">Search</a>
                
                <a href="/about" class="item">About</a>
                
            </div>
            
            <div class="group">
                <h2 class="title">Me</h2>
                
                <a target="_blank" rel="noopener" href="https://github.com/kinferiority" class="item">GitHub</a>
                
                <a href="mailto:Kinferiority@outlook.com" class="item">Email</a>
                
            </div>
            
        </div>
        <span>&copy; 2023 Kjr<br>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> </span>
        
        
            <br>
            <div class="color-scheme-toggle" role="radiogroup" id="theme-color-scheme-toggle">
                <label>
                    <input type="radio" value="light">
                    <span>Light</span>
                </label>
                <label>
                    <input type="radio" value="dark">
                    <span>Dark</span>
                </label>
                <label>
                    <input type="radio" value="auto">
                    <span>Auto</span>
                </label>
            </div>
        
    </div>
</footer>


        
<script src="/js/main.js"></script>

        
        
        

        
        <script src="https://unpkg.com/scrollreveal"></script>
        <script>
            window.addEventListener('load', () => {
                ScrollReveal({ delay: 250, reset: true, easing: 'cubic-bezier(0, 0, 0, 1)' })
                ScrollReveal().reveal('.post-list-item .cover-img img')
                ScrollReveal().reveal('.post-list-item, .card, .content p img, .content .block-large img', { distance: '60px', origin: 'bottom', duration: 800 })
            })
        </script>
        
    </body>
</html>